{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f5bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "from ptflops import get_model_complexity_info\n",
    "import os\n",
    "import sys\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208394d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3682df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_cnn='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom CNN model. This is the architecture of the model: \n",
    "CNN(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (7): ReLU(inplace=True)\n",
    "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (10): ReLU(inplace=True)\n",
    "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (13): ReLU(inplace=True)\n",
    "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Dropout(p=0.5, inplace=False)\n",
    "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): Dropout(p=0.5, inplace=False)\n",
    "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  )\n",
    ")\n",
    "I want to identify hyperparameter ranges for training and finetuning this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format and title the parameters as \n",
    "Training and Fine-Tuning respectively:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "789392a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_MLP='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom MLP model. This is the architecture of the model: \n",
    "MLP(\n",
    "  (fc1): Linear(in_features=150528, out_features=4096, bias=True)\n",
    "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  (relu): ReLU()\n",
    "  (dropout): Dropout(p=0.5, inplace=False)\n",
    ")\n",
    "I want to identify hyperparameter ranges for training and finetuning this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format and title the parameters as \n",
    "Training and Fine-Tuning respectively:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb36cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_ResNet='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom ResNet model. This is the architecture of the model: \n",
    "ResNet5(\n",
    "  (layer1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
    "  (layer2): BasicBlock(\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential()\n",
    "  )\n",
    "  (layer3): BasicBlock(\n",
    "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer4): BasicBlock(\n",
    "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer5): BasicBlock(\n",
    "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    ")\n",
    "\n",
    "I want to identify hyperparameter ranges for training and finetuning this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format and title the parameters as \n",
    "Training and Fine-Tuning respectively:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39df62bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_cnn_modified='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom CNN model. This is the architecture of the model: \n",
    "ModifiedCNN(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU(inplace=True)\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (6): ReLU(inplace=True)\n",
    "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (10): ReLU(inplace=True)\n",
    "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (13): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
    "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (15): ReLU(inplace=True)\n",
    "    (16): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (19): ReLU(inplace=True)\n",
    "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Dropout(p=0.5, inplace=False)\n",
    "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): Dropout(p=0.5, inplace=False)\n",
    "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  )\n",
    ")\n",
    "I want to identify hyperparameter ranges for training and finetuning this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format and title the parameters as \n",
    "Training and Fine-Tuning respectively:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd37f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_MLP_modified='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom CNN model. This is the architecture of the model: \n",
    "ModifiedMLP(\n",
    "  (fc1): Linear(in_features=150528, out_features=2048, bias=True)\n",
    "  (fc2): Linear(in_features=2048, out_features=4096, bias=True)\n",
    "  (fc3): Linear(in_features=4096, out_features=2048, bias=True)\n",
    "  (fc4): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
    "  (dropout1): Dropout(p=0.4, inplace=False)\n",
    "  (dropout2): Dropout(p=0.6, inplace=False)\n",
    "  (batch_norm1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (batch_norm2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (batch_norm3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    ")\n",
    "\n",
    "I want to identify hyperparameter ranges for training and finetuning this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format and title the parameters as \n",
    "Training and Fine-Tuning respectively:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d129ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_ResNet_modified='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom ResNet model. This is the architecture of the model: \n",
    "ModifiedResNet(\n",
    "  (layer1): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
    "  (layer2): DilatedBlock(\n",
    "    (conv1): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer3): DilatedBlock(\n",
    "    (conv1): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer4): DilatedBlock(\n",
    "    (conv1): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
    "    (skip): Sequential()\n",
    "  )\n",
    "  (layer5): DilatedBlock(\n",
    "    (conv1): Conv2d(512, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(1024, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
    ")\n",
    "\n",
    "I want to identify hyperparameter ranges for training and finetuning this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format and title the parameters as \n",
    "Training and Fine-Tuning respectively:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a35a191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot2='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "The dataset I'm using is ObjectNet, known for its challenging viewpoints and backgrounds.\n",
    "Now I have changed the model to a vision transformer vit please consider this change when you reasyon the hyperparameters.\n",
    "The goal is to define hyperparameter search space ranges for hyperopt.\n",
    "Let's think step by step for each hyperparameters. \n",
    "Please consider the dataset and the model which are used as these are critical for the task.\n",
    "I need to specify ranges for the following hyperparameters:\n",
    "  1. Learning Rate\n",
    "  2. Batch Size\n",
    "  3. Number of Epochs\n",
    "  4. Optimizer (Adam or SGD)\n",
    "  5. Loss Function (CrossEntropyLoss, MSE, Hinge)\n",
    "  6. Learning Rate Scheduler (StepLR or ReduceLROnPlateau)\n",
    "  7. Step Size for Learning Rate Scheduler\n",
    "  8. Gamma for Learning Rate Scheduler\n",
    "  9. Momentum for SGD Optimizer\n",
    "\n",
    "Please format you answer in JSON like this:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimizer\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"\n",
    "}\n",
    "\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca1a9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt2 = \"\"\"\n",
    "I want you to be a machine learninig expert.\n",
    "You have the knowledge of training and fine-tuning various machine learning models \n",
    "for sentiment analysis tasks in the financial domain.\n",
    "I want you to use this knowledge to aid me in an experiment.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt2 = \"\"\"\n",
    "Task: I want to understand the finiancial market structure to \n",
    "      make investments using information from financial news.\n",
    "\n",
    "Objective:\n",
    "I aim to fine-tune the FinancialBERT model on the financial_phrasebank dataset for sentiment analysis.\n",
    "Please provide hyperparameters that can help me fine-tune the model effectively on this dataset.\n",
    "\n",
    "Dataset Description:\n",
    "I will be using the financial_phrasebank dataset, which contains \n",
    "4840 sentences from English language financial news.\n",
    "The sentences are categorized by sentiment, and \n",
    "the dataset includes both positive and negative sentiment labels.\n",
    "The dataset's annotations have an agreement rate of 5-8 annotators.\n",
    "\n",
    "Model details:\n",
    "I plan to use the FinancialBERT model, which is a BERT model pre-trained on a large corpus of financial texts.\n",
    "The model was trained on the following financial data sources:\n",
    "- TRC2-financial: 1.8M news articles published by Reuters between 2008 and 2010.\n",
    "- Bloomberg News: 400,000 articles between 2006 and 2013.\n",
    "- Corporate Reports: 192,000 transcripts (10-K & 10-Q)\n",
    "- Earning Calls: 42,156 documents.\n",
    "\n",
    "Format your answer in strict JSON format with the following:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimizer\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084cbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt1 = \"\"\"\n",
    "I want you to be a Machine Learning expert.\n",
    "You have the knowledge of training and fine-tuning various machine learning models for various tasks.\n",
    "I want you to use this knowledge for aiding me in an experiment.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt1 = \"\"\"\n",
    "Task: I want to perform chest X-ray image classification for medical diagnosis.\n",
    "Objective:\n",
    "I want to fine-tune a model on a new chest X-ray dataset that I will provide.\n",
    "Please suggest some hyperparameters to finetune this model on the dataset for image classification.\n",
    "\n",
    "Dataset Description:\n",
    "I am using a new chest X-ray dataset collected from various hospitals.\n",
    "The dataset contains 10,000 chest X-ray images with various medical conditions.\n",
    "Classes include pneumonia, normal, and other lung diseases.\n",
    "The dataset is split into train, validation, and test sets.\n",
    "\n",
    "Model description:\n",
    "I am using the regnet_x_16gf model, which has an accuracy of 80% on ImageNet-1K.\n",
    "\n",
    "Model performance on a benchmark:\n",
    "Accuracy (top-1) on ImageNet-1K: 77.04%\n",
    "Accuracy (top-5) on ImageNet-1K: 93.44%\n",
    "Minimum size: height=1, width=1\n",
    "Number of parameters: 9,190,136\n",
    "GFLOPS: The model requires 1.60 GFLOPS (giga floating-point operations per second) for computation.\n",
    "File size: The model's file size is 35.3 MB.\n",
    "\n",
    "Format your answer in strict JSON format with the following:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimizer\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8983af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt=\"\"\"I want you to be a Machine Learning expert. \n",
    "# You have the knowledge of training and finetuining various machine learning models for various tasks. \n",
    "# I want you to use this knowledge for aiding me in an experiment\n",
    "# \"\"\"\n",
    "# user_prompt=\"\"\"\n",
    "\n",
    "# Task: I want to perform reaf-time image classification to be deployed on a security camera.\n",
    "\n",
    "# Objective:\n",
    "# I want you to specify the ranges for the hyperparameter search space. I just want the high and low for the search space as i am going to use the hp.loguniform function.I am using the hyperopt library to perform this task.\n",
    "\n",
    "# Dataset Description:\n",
    "# I am using the ObjectNet dataset.\n",
    "# A new kind of vision dataset borrowing the idea of controls from other areas of science.\n",
    "# No training set, only a test set! Put your vision system through its paces.\n",
    "# Collected to intentionally show objects from new viewpoints on new backgrounds.\n",
    "# 50,000 image test set, same as ImageNet, with controls for rotation, background, and viewpoint.\n",
    "# 313 object classes with 113 overlapping ImageNet\n",
    "# Large performance drop, what you can expect from vision systems in the real world!\n",
    "# Robust to fine-tuning and a very difficult transfer learning problem\n",
    "\n",
    "# Model description:\n",
    "# I am using a regnet_x_16gf model. which has an accuracy of 80% on image net 1k.\n",
    "\n",
    "# Model performance on a benchmark:\n",
    "# Accuracy (top-1) on ImageNet-1K: 77.04%\n",
    "# Accuracy (top-5) on ImageNet-1K: 93.44%\n",
    "# Minimum size: height=1, width=1\n",
    "# Number of parameters: 9,190,136\n",
    "# Recipe: The recipe for the model is not provided.\n",
    "# Link: The link to the model documentation is not provided.\n",
    "# GFLOPS: The model requires 1.60 GFLOPS (giga floating-point operations per second) for computation.\n",
    "# File size: The model's file size is 35.3 MB.\n",
    "\n",
    "# Format your answer in strict JSON format with the following:\n",
    "# {\n",
    "#     \"learning_rate\":\"\"\n",
    "#     \"batch_size\":\"\"\n",
    "#     \"num_epochs\":\"\"\n",
    "#     \"optimiser\":\"\"\n",
    "#     \"loss_function\":\"\"\n",
    "#     \"scheduler\":\"\"\n",
    "#     \"step_size\":\"\"\n",
    "#     \"gamma\":\"\"\n",
    "#     \"learning_rate\":\"\"\n",
    "#     \"momentum\":\"\"    \n",
    "# }\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b59646e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_file_name = f'output_prompt_cnn.txt'\n",
    "output_file = open(output_file_name, 'w')\n",
    "sys.stdout = output_file\n",
    "\n",
    "num_executions = 5\n",
    "temp = 0\n",
    "\n",
    "training_df = pd.DataFrame(columns=['Learning Rate', 'Momentum', 'Batch Size', 'Num Epochs', 'Optimizer',\n",
    "                                   'Loss Function', 'Scheduler', 'Step Size', 'Gamma'])\n",
    "fine_tuning_df = pd.DataFrame(columns=['Learning Rate', 'Momentum', 'Batch Size', 'Num Epochs', 'Optimizer',\n",
    "                                      'Loss Function', 'Scheduler', 'Step Size', 'Gamma'])\n",
    "\n",
    "\n",
    "for i in range(num_executions):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "#                 {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt_cot_cnn}\n",
    "            ],\n",
    "            temperature=temp\n",
    "        )\n",
    "    except Exception:\n",
    "        sleep(3)\n",
    "        print('Limit exceeded!')\n",
    "        continue\n",
    "\n",
    "    completion = response.choices[0]['message']['content']\n",
    "    print(completion)\n",
    "\n",
    "    start_index = completion.find('{')\n",
    "    end_index = completion.rfind('}') + 1\n",
    "    json_string = completion[start_index:end_index]\n",
    "\n",
    "    try:\n",
    "        completion_dict = json.loads(json_string)\n",
    "\n",
    "        learning_rate = completion_dict.get('learning_rate')\n",
    "        momentum = completion_dict.get('momentum')\n",
    "        batch_size = completion_dict.get('batch_size')\n",
    "        num_epochs = completion_dict.get('num_epochs')\n",
    "        optimizer = completion_dict.get('optimizer')\n",
    "        loss_function = completion_dict.get('loss_function')\n",
    "        scheduler = completion_dict.get('scheduler')\n",
    "        step_size = completion_dict.get('step_size')\n",
    "        gamma = completion_dict.get('gamma')\n",
    "\n",
    "\n",
    "        if \"Training\" in completion:\n",
    "            training_df.loc[i] = [learning_rate, momentum, batch_size, num_epochs, optimizer,\n",
    "                                 loss_function, scheduler, step_size, gamma]\n",
    "        elif \"Fine-Tuning\" in completion:\n",
    "            fine_tuning_df.loc[i] = [learning_rate, momentum, batch_size, num_epochs, optimizer,\n",
    "                                     loss_function, scheduler, step_size, gamma]\n",
    "\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print('Could not decode the completion as JSON.')\n",
    "output_file.close()\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "\n",
    "\n",
    "training_df.to_csv('prompt_results/training_results.csv', index=False)\n",
    "fine_tuning_df.to_csv('prompt_results/fine_tuning_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d7948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
