{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f649b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "from ptflops import get_model_complexity_info\n",
    "import os\n",
    "import sys\n",
    "from time import sleep\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b03432",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a6bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cnn_ifcresults ='''\n",
    "In machine learning, hyperparameters are crucial configuration settings used to structure machine learning models. \n",
    "While model parameters are learned during training, hyperparameters must be set prior to the training process. \n",
    "They influence the overall performance, speed, and quality of the training process and the resulting model. \n",
    "\n",
    "Here's the architecture of the custom Convolutional Neural Network (CNN) model under consideration:\n",
    "CNN(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (7): ReLU(inplace=True)\n",
    "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (10): ReLU(inplace=True)\n",
    "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (13): ReLU(inplace=True)\n",
    "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Dropout(p=0.5, inplace=False)\n",
    "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): Dropout(p=0.5, inplace=False)\n",
    "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  )\n",
    ")\n",
    "Given this context, provide optimized hyperparameters tailored for training this model on the ImageNet dataset, \n",
    "ensuring that the model generalizes well while preventing overfitting. \n",
    "Your insights into the choices of hyperparameters, \n",
    "especially considering the specified architecture, will be valuable.\n",
    "\n",
    "Format recommended hyperparameters and their corresponding values in a JSON format:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimiser\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"    \n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e17296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_mlp_ifcresults ='''\n",
    "In machine learning, hyperparameters are crucial configuration settings used to structure machine learning models. \n",
    "While model parameters are learned during training, hyperparameters must be set prior to the training process. \n",
    "They influence the overall performance, speed, and quality of the training process and the resulting model. \n",
    "\n",
    "Here's the architecture of the custom MLP model under consideration:\n",
    "MLP(\n",
    "  (fc1): Linear(in_features=150528, out_features=4096, bias=True)\n",
    "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  (relu): ReLU()\n",
    "  (dropout): Dropout(p=0.5, inplace=False)\n",
    ")\n",
    "Given this context, provide optimized hyperparameters tailored for training this model on the ImageNet dataset, \n",
    "ensuring that the model generalizes well while preventing overfitting. \n",
    "Your insights into the choices of hyperparameters, \n",
    "especially considering the specified architecture, will be valuable.\n",
    "\n",
    "Format recommended hyperparameters and their corresponding values in a JSON format:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimiser\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"    \n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0cfe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_resnet_ifcresults ='''\n",
    "In machine learning, hyperparameters are crucial configuration settings used to structure machine learning models. \n",
    "While model parameters are learned during training, hyperparameters must be set prior to the training process. \n",
    "They influence the overall performance, speed, and quality of the training process and the resulting model. \n",
    "\n",
    "Here's the architecture of the custom ResNet model under consideration:\n",
    "ResNet5(\n",
    "  (layer1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
    "  (layer2): BasicBlock(\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential()\n",
    "  )\n",
    "  (layer3): BasicBlock(\n",
    "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer4): BasicBlock(\n",
    "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer5): BasicBlock(\n",
    "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    ")\n",
    "Given this context, provide optimized hyperparameters tailored for training this model on the ImageNet dataset, \n",
    "ensuring that the model generalizes well while preventing overfitting. \n",
    "Your insights into the choices of hyperparameters, \n",
    "especially considering the specified architecture, will be valuable.\n",
    "\n",
    "Format recommended hyperparameters and their corresponding values in a JSON format:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimiser\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"    \n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397f4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_modified_cnn_ifcresults ='''\n",
    "In machine learning, hyperparameters are crucial configuration settings used to structure machine learning models. \n",
    "While model parameters are learned during training, hyperparameters must be set prior to the training process. \n",
    "They influence the overall performance, speed, and quality of the training process and the resulting model. \n",
    "\n",
    "Here's the architecture of the custom CNN model under consideration:\n",
    "ModifiedCNN(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU(inplace=True)\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (6): ReLU(inplace=True)\n",
    "\n",
    "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (10): ReLU(inplace=True)\n",
    "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (13): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
    "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (15): ReLU(inplace=True)\n",
    "    (16): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (19): ReLU(inplace=True)\n",
    "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Dropout(p=0.5, inplace=False)\n",
    "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): Dropout(p=0.5, inplace=False)\n",
    "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  )\n",
    ")\n",
    "Given this context, provide optimized hyperparameters tailored for training this model on the ImageNet dataset, \n",
    "ensuring that the model generalizes well while preventing overfitting. \n",
    "Your insights into the choices of hyperparameters, \n",
    "especially considering the specified architecture, will be valuable.\n",
    "\n",
    "Format recommended hyperparameters and their corresponding values in a JSON format:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimiser\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"    \n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa8eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_modified_cnn_ifcresults ='''\n",
    "In machine learning, hyperparameters are crucial configuration settings used to structure machine learning models. \n",
    "While model parameters are learned during training, hyperparameters must be set prior to the training process. \n",
    "They influence the overall performance, speed, and quality of the training process and the resulting model. \n",
    "\n",
    "Here's the architecture of the custom CNN model under consideration:\n",
    "ModifiedCNN(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU(inplace=True)\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (6): ReLU(inplace=True)\n",
    "\n",
    "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (10): ReLU(inplace=True)\n",
    "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (13): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
    "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (15): ReLU(inplace=True)\n",
    "    (16): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (19): ReLU(inplace=True)\n",
    "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Dropout(p=0.5, inplace=False)\n",
    "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): Dropout(p=0.5, inplace=False)\n",
    "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  )\n",
    ")\n",
    "Given this context, provide optimized hyperparameters tailored for training this model on the ImageNet dataset, \n",
    "ensuring that the model generalizes well while preventing overfitting. \n",
    "Your insights into the choices of hyperparameters, \n",
    "especially considering the specified architecture, will be valuable.\n",
    "\n",
    "Format recommended hyperparameters and their corresponding values in a JSON format:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimiser\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"    \n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80222d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_modified_mlp_ifcresults ='''\n",
    "In machine learning, hyperparameters are crucial configuration settings used to structure machine learning models. \n",
    "While model parameters are learned during training, hyperparameters must be set prior to the training process. \n",
    "They influence the overall performance, speed, and quality of the training process and the resulting model. \n",
    "\n",
    "Here's the architecture of the custom MLP model under consideration:\n",
    "ModifiedMLP(\n",
    "  (fc1): Linear(in_features=150528, out_features=2048, bias=True)\n",
    "  (fc2): Linear(in_features=2048, out_features=4096, bias=True)\n",
    "  (fc3): Linear(in_features=4096, out_features=2048, bias=True)\n",
    "  (fc4): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
    "  (dropout1): Dropout(p=0.4, inplace=False)\n",
    "  (dropout2): Dropout(p=0.6, inplace=False)\n",
    "  (batch_norm1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (batch_norm2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (batch_norm3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    ")\n",
    "\n",
    "Given this context, provide optimized hyperparameters tailored for training this model on the ImageNet dataset, \n",
    "ensuring that the model generalizes well while preventing overfitting. \n",
    "Your insights into the choices of hyperparameters, \n",
    "especially considering the specified architecture, will be valuable.\n",
    "\n",
    "Format recommended hyperparameters and their corresponding values in a JSON format:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimiser\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"    \n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae0e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_modified_resnet_ifcresults ='''\n",
    "In machine learning, hyperparameters are crucial configuration settings used to structure machine learning models. \n",
    "While model parameters are learned during training, hyperparameters must be set prior to the training process. \n",
    "They influence the overall performance, speed, and quality of the training process and the resulting model. \n",
    "\n",
    "Here's the architecture of the custom ResNet model under consideration:\n",
    "ModifiedResNet(\n",
    "  (layer1): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
    "  (layer2): DilatedBlock(\n",
    "    (conv1): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer3): DilatedBlock(\n",
    "    (conv1): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer4): DilatedBlock(\n",
    "    (conv1): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
    "    (skip): Sequential()\n",
    "  )\n",
    "  (layer5): DilatedBlock(\n",
    "    (conv1): Conv2d(512, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(1024, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
    ")\n",
    "\n",
    "Given this context, provide optimized hyperparameters tailored for training this model on the ImageNet dataset, \n",
    "ensuring that the model generalizes well while preventing overfitting. \n",
    "Your insights into the choices of hyperparameters, \n",
    "especially considering the specified architecture, will be valuable.\n",
    "\n",
    "Format recommended hyperparameters and their corresponding values in a JSON format:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimiser\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"    \n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e748d111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae537c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd2735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "747dcf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_cnn='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom CNN model. This is the architecture of the model: \n",
    "CNN(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (7): ReLU(inplace=True)\n",
    "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (10): ReLU(inplace=True)\n",
    "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (13): ReLU(inplace=True)\n",
    "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Dropout(p=0.5, inplace=False)\n",
    "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): Dropout(p=0.5, inplace=False)\n",
    "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  )\n",
    ")\n",
    "I want you to provide optimal hyperparameters for training this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9069de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_MLP='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom MLP model. This is the architecture of the model: \n",
    "MLP(\n",
    "  (fc1): Linear(in_features=150528, out_features=4096, bias=True)\n",
    "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  (relu): ReLU()\n",
    "  (dropout): Dropout(p=0.5, inplace=False)\n",
    ")\n",
    "I want to you to provide optimal hyperparameter for training this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba527275",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_ResNet='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom ResNet model. This is the architecture of the model: \n",
    "ResNet5(\n",
    "  (layer1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
    "  (layer2): BasicBlock(\n",
    "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential()\n",
    "  )\n",
    "  (layer3): BasicBlock(\n",
    "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer4): BasicBlock(\n",
    "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer5): BasicBlock(\n",
    "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    ")\n",
    "\n",
    "I want you to provide optimal hyperparameters for training this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6abc043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_cnn_modified='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom CNN model. This is the architecture of the model: \n",
    "ModifiedCNN(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU(inplace=True)\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (6): ReLU(inplace=True)\n",
    "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (10): ReLU(inplace=True)\n",
    "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (13): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
    "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (15): ReLU(inplace=True)\n",
    "    (16): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (19): ReLU(inplace=True)\n",
    "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Dropout(p=0.5, inplace=False)\n",
    "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): Dropout(p=0.5, inplace=False)\n",
    "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  )\n",
    ")\n",
    "I want you to provide optimal hyperparameters for training this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bacce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_MLP_modified='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom CNN model. This is the architecture of the model: \n",
    "ModifiedMLP(\n",
    "  (fc1): Linear(in_features=150528, out_features=2048, bias=True)\n",
    "  (fc2): Linear(in_features=2048, out_features=4096, bias=True)\n",
    "  (fc3): Linear(in_features=4096, out_features=2048, bias=True)\n",
    "  (fc4): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
    "  (dropout1): Dropout(p=0.4, inplace=False)\n",
    "  (dropout2): Dropout(p=0.6, inplace=False)\n",
    "  (batch_norm1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (batch_norm2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (batch_norm3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    ")\n",
    "\n",
    "I want you to provide optimal hyperparameters for training this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format:\n",
    "{\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c4d4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot_ResNet_modified='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "I am using a custom ResNet model. This is the architecture of the model: \n",
    "ModifiedResNet(\n",
    "  (layer1): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
    "  (layer2): DilatedBlock(\n",
    "    (conv1): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer3): DilatedBlock(\n",
    "    (conv1): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer4): DilatedBlock(\n",
    "    (conv1): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
    "    (skip): Sequential()\n",
    "  )\n",
    "  (layer5): DilatedBlock(\n",
    "    (conv1): Conv2d(512, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(1024, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (globalpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
    ")\n",
    "\n",
    "I want you to provide optimal hyperparameters for training this custom model on the \n",
    "ImageNet dataset.Please specify the reason and finally format the answer in this format:\n",
    "    \"learning_rate\":\"\"\n",
    "    \"batch_size\":\"\"\n",
    "    \"num_epochs\":\"\"\n",
    "    \"optimiser\":\"\"\n",
    "    \"loss_function\":\"\"\n",
    "    \"scheduler\":\"\"\n",
    "    \"step_size\":\"\"\n",
    "    \"gamma\":\"\"\n",
    "    \"learning_rate\":\"\"\n",
    "    \"momentum\":\"\"    \n",
    "}\n",
    "\n",
    "Take a deep breath and work on this problem step by step by step.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fba20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cot2='''\n",
    "I want to perform real-time image classification on a security camera.\n",
    "The dataset I'm using is ObjectNet, known for its challenging viewpoints and backgrounds.\n",
    "Now I have changed the model to a vision transformer vit please consider this change when you reasyon the hyperparameters.\n",
    "The goal is to define hyperparameter search space ranges for hyperopt.\n",
    "Let's think step by step for each hyperparameters. \n",
    "Please consider the dataset and the model which are used as these are critical for the task.\n",
    "I need to specify ranges for the following hyperparameters:\n",
    "  1. Learning Rate\n",
    "  2. Batch Size\n",
    "  3. Number of Epochs\n",
    "  4. Optimizer (Adam or SGD)\n",
    "  5. Loss Function (CrossEntropyLoss, MSE, Hinge)\n",
    "  6. Learning Rate Scheduler (StepLR or ReduceLROnPlateau)\n",
    "  7. Step Size for Learning Rate Scheduler\n",
    "  8. Gamma for Learning Rate Scheduler\n",
    "  9. Momentum for SGD Optimizer\n",
    "\n",
    "Please format you answer in JSON like this:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimizer\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"\n",
    "}\n",
    "\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7606d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt2 = \"\"\"\n",
    "I want you to be a machine learninig expert.\n",
    "You have the knowledge of training and fine-tuning various machine learning models \n",
    "for sentiment analysis tasks in the financial domain.\n",
    "I want you to use this knowledge to aid me in an experiment.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt2 = \"\"\"\n",
    "Task: I want to understand the finiancial market structure to \n",
    "      make investments using information from financial news.\n",
    "\n",
    "Objective:\n",
    "I aim to fine-tune the FinancialBERT model on the financial_phrasebank dataset for sentiment analysis.\n",
    "Please provide hyperparameters that can help me fine-tune the model effectively on this dataset.\n",
    "\n",
    "Dataset Description:\n",
    "I will be using the financial_phrasebank dataset, which contains \n",
    "4840 sentences from English language financial news.\n",
    "The sentences are categorized by sentiment, and \n",
    "the dataset includes both positive and negative sentiment labels.\n",
    "The dataset's annotations have an agreement rate of 5-8 annotators.\n",
    "\n",
    "Model details:\n",
    "I plan to use the FinancialBERT model, which is a BERT model pre-trained on a large corpus of financial texts.\n",
    "The model was trained on the following financial data sources:\n",
    "- TRC2-financial: 1.8M news articles published by Reuters between 2008 and 2010.\n",
    "- Bloomberg News: 400,000 articles between 2006 and 2013.\n",
    "- Corporate Reports: 192,000 transcripts (10-K & 10-Q)\n",
    "- Earning Calls: 42,156 documents.\n",
    "\n",
    "Format your answer in strict JSON format with the following:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimizer\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1866e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt1 = \"\"\"\n",
    "I want you to be a Machine Learning expert.\n",
    "You have the knowledge of training and machine learning models for various computer vision tasks.\n",
    "I want you to use this knowledge for aiding me in an experiment.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt1 = \"\"\"\n",
    "Task: I want to train a custom model on the ImageNet dataset. I will provide the architecture of the model \n",
    "in the model description section.\n",
    "Objective: I want the optimal hyperparameters for training the following model\n",
    "Model Description:\n",
    "\n",
    "Dataset Description:\n",
    "I am going to the ImageNet 1k dataset.\n",
    "\n",
    "Format your answer in strict JSON format with the following:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimizer\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd335d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt=\"\"\"I want you to be a Machine Learning expert. \n",
    "# You have the knowledge of training and finetuining various machine learning models for various tasks. \n",
    "# I want you to use this knowledge for aiding me in an experiment\n",
    "# \"\"\"\n",
    "# user_prompt=\"\"\"\n",
    "\n",
    "# Task: I want to perform reaf-time image classification to be deployed on a security camera.\n",
    "\n",
    "# Objective:\n",
    "# I want you to specify the ranges for the hyperparameter search space. I just want the high and low for the search space as i am going to use the hp.loguniform function.I am using the hyperopt library to perform this task.\n",
    "\n",
    "# Dataset Description:\n",
    "# I am using the ObjectNet dataset.\n",
    "# A new kind of vision dataset borrowing the idea of controls from other areas of science.\n",
    "# No training set, only a test set! Put your vision system through its paces.\n",
    "# Collected to intentionally show objects from new viewpoints on new backgrounds.\n",
    "# 50,000 image test set, same as ImageNet, with controls for rotation, background, and viewpoint.\n",
    "# 313 object classes with 113 overlapping ImageNet\n",
    "# Large performance drop, what you can expect from vision systems in the real world!\n",
    "# Robust to fine-tuning and a very difficult transfer learning problem\n",
    "\n",
    "# Model description:\n",
    "# I am using a regnet_x_16gf model. which has an accuracy of 80% on image net 1k.\n",
    "\n",
    "# Model performance on a benchmark:\n",
    "# Accuracy (top-1) on ImageNet-1K: 77.04%\n",
    "# Accuracy (top-5) on ImageNet-1K: 93.44%\n",
    "# Minimum size: height=1, width=1\n",
    "# Number of parameters: 9,190,136\n",
    "# Recipe: The recipe for the model is not provided.\n",
    "# Link: The link to the model documentation is not provided.\n",
    "# GFLOPS: The model requires 1.60 GFLOPS (giga floating-point operations per second) for computation.\n",
    "# File size: The model's file size is 35.3 MB.\n",
    "\n",
    "# Format your answer in strict JSON format with the following:\n",
    "# {\n",
    "#     \"learning_rate\":\"\"\n",
    "#     \"batch_size\":\"\"\n",
    "#     \"num_epochs\":\"\"\n",
    "#     \"optimiser\":\"\"\n",
    "#     \"loss_function\":\"\"\n",
    "#     \"scheduler\":\"\"\n",
    "#     \"step_size\":\"\"\n",
    "#     \"gamma\":\"\"\n",
    "#     \"learning_rate\":\"\"\n",
    "#     \"momentum\":\"\"    \n",
    "# }\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "222c952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"user\", \"content\": \"What is the relationship between hyperparameters and a models layers?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"\"The relationship between hyperparameters and a model's layers, particularly in the context of deep learning, can be understood in several dimensions:\n",
    "\n",
    "1. **Definition**:\n",
    "   - **Model's layers**: These are the building blocks of a neural network. Each layer consists of a set of neurons, and these layers can be of various types such as dense (fully connected), convolutional, recurrent, etc., depending on the architecture.\n",
    "   - **Hyperparameters**: These are the parameters whose values are set before the learning process begins, as opposed to model parameters which are learned during training. They define high-level properties of the training process and the architecture of the model.\n",
    "\n",
    "2. **Specification**:\n",
    "   - Many aspects of a model's layers are determined by hyperparameters. For example:\n",
    "     - **Number of layers**: How deep the network is.\n",
    "     - **Number of neurons/nodes** in each layer.\n",
    "     - **Type of layer**: Whether you are using a convolutional layer, recurrent layer, or a simple dense layer.\n",
    "     - **Activation function** used in each layer (e.g., ReLU, sigmoid, tanh).\n",
    "     - **Dropout rate**: The proportion of nodes which are randomly \"dropped\" in dropout layers, to prevent overfitting.\n",
    "     - **Kernel size**, **stride**, and **padding** in convolutional layers.\n",
    "\n",
    "3. **Training**:\n",
    "   - Hyperparameters also dictate how the model is trained. Examples include:\n",
    "     - **Learning rate**: How quickly the model updates its weights.\n",
    "     - **Batch size**: Number of training samples used in one forward/backward pass.\n",
    "     - **Number of epochs**: How many times the training data is passed forward and backward through the neural network.\n",
    "     - **Optimization algorithm**: Such as SGD, Adam, or RMSprop.\n",
    "     - **Loss function**: Defines the measure of difference between predicted and true values.\n",
    "\n",
    "4. **Regularization**:\n",
    "   - Hyperparameters can control regularization techniques that prevent overfitting:\n",
    "     - **L1/L2 regularization strengths**: Penalties on the magnitude of model parameters.\n",
    "     - **Dropout rate**: As mentioned before, the proportion of nodes to drop during training to prevent co-adaptation of neurons.\n",
    "\n",
    "5. **Performance & Generalization**:\n",
    "   - Properly setting hyperparameters is critical for model performance. Inappropriate hyperparameter values can lead to issues like overfitting (where the model performs well on training data but poorly on unseen data) or underfitting (where the model doesn't perform well even on the training data).\n",
    "   - The architecture-related hyperparameters determine the capacity of the model. A model with too many layers or neurons might be too complex and overfit to the training data, while a model with too few might not capture underlying patterns and underfit.\n",
    "\n",
    "6. **Tuning**:\n",
    "   - While the initial choice of hyperparameters is often based on heuristic or prior experience, they are typically refined using processes like grid search, random search, or more sophisticated methods like Bayesian optimization to find an optimal set that maximizes performance on a validation set.\n",
    "\n",
    "In summary, hyperparameters guide and define the architecture of a model's layers and the training process. They play a critical role in determining how well a model performs and generalizes to new, unseen data.\"\"\"},\n",
    " {\"role\": \"user\", \"content\": \"\"\"\"How does the \"model's architecture\" influence the \"hyperparameters\" for training? \"\"\"},\n",
    " {\"role\": \"assistant\", \"content\": \"\"\"\"The model's architecture and the choice of hyperparameters are intertwined in various ways. The architecture, which represents the structural design of the model, often dictates or heavily influences the suitable values or ranges for certain hyperparameters. Here's how the model's architecture can influence the choice of hyperparameters:\n",
    "\n",
    "1. **Model Complexity**:\n",
    "   - **Larger architectures**: Models with more layers or more neurons per layer generally have more capacity (ability to fit a wide range of functions). Such models might need stronger regularization techniques, like dropout or weight decay, to prevent overfitting.\n",
    "   - **Smaller architectures**: Less complex models might not capture the nuances of the data if they're too simple, leading to underfitting. In such cases, reducing regularization might be appropriate.\n",
    "\n",
    "2. **Layer Type**:\n",
    "   - **Convolutional Neural Networks (CNNs)**: Hyperparameters such as filter size, number of filters, stride, padding, and pooling type are specific to CNNs.\n",
    "   - **Recurrent Neural Networks (RNNs)**: Hyperparameters like sequence length, type of RNN cell (LSTM, GRU, etc.), and whether to use bidirectional RNNs come into play.\n",
    "\n",
    "3. **Depth of the Network**:\n",
    "   - **Deep Networks**: The learning rate, initialization method, and choice of optimizer can be crucial. For very deep networks, techniques like residual connections might be used, which also introduces additional hyperparameters.\n",
    "\n",
    "4. **Normalization Techniques**:\n",
    "   - If the architecture includes normalization layers like Batch Normalization or Layer Normalization, hyperparameters such as momentum and epsilon for these techniques become relevant.\n",
    "\n",
    "5. **Activation Functions**:\n",
    "   - Different architectures might favor certain activation functions. For example, CNNs often use ReLU or its variants, while RNNs might use tanh or ReLU. The choice of activation can influence other hyperparameters like the learning rate.\n",
    "\n",
    "6. **Training Stability and Convergence**:\n",
    "   - Some architectures, especially deeper ones, might be more sensitive to the choice of initialization and optimizer. For instance, certain initialization methods like He or Xavier initialization are designed based on the activation function used in the network.\n",
    "\n",
    "7. **Optimizers**:\n",
    "   - More complex models might benefit from adaptive learning rate optimizers like Adam, RMSprop, etc., rather than simple SGD. Each optimizer comes with its own set of hyperparameters, such as learning rate, momentum, or decay rates.\n",
    "\n",
    "8. **Task Specificity**:\n",
    "   - For tasks like sequence-to-sequence learning, architectures like encoder-decoder models introduce hyperparameters related to both the encoder and decoder components.\n",
    "\n",
    "9. **Regularization Techniques**:\n",
    "   - Depending on the architecture, certain regularization techniques might be more appropriate. For instance, spatial dropout might be more suited for convolutional layers.\n",
    "\n",
    "10. **Transfer Learning**:\n",
    "   - When utilizing pre-trained models, the learning rate for the pre-trained layers is often set much lower than for the newly added layers to retain the previously learned features.\n",
    "\n",
    "In essence, the chosen architecture not only dictates certain hyperparameters specific to the structure itself but also influences the optimal values of general hyperparameters. Proper co-optimization of architecture and hyperparameters is often necessary to achieve the best model performance.\"\"\"}, \n",
    "    {\"role\": \"user\", \"content\": \"\"\"\"Give me an example of how the models architecture influence a hyperparameter during initialising a training scheme for the model? \"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"\"Certainly! Let's consider a Convolutional Neural Network (CNN) designed for image classification. \n",
    "\n",
    "### Model's Architecture:\n",
    "Imagine a deep CNN that consists of several convolutional layers followed by pooling layers, then some fully connected layers, and finally a softmax layer for classification. This network uses the ReLU (Rectified Linear Unit) activation function throughout.\n",
    "\n",
    "### Hyperparameter influenced by the Architecture: Weight Initialization\n",
    "\n",
    "One of the challenges with deep networks, especially those using the ReLU activation function, is the vanishing or exploding gradients problem. Improper weight initialization can lead to all activations becoming zeros (dying ReLUs) or very large values, both of which can impede effective training.\n",
    "\n",
    "For networks using the ReLU activation, a common initialization method is the **He Initialization** (named after Kaiming He, its proponent). This method initializes weights of the network with a variance of `2/n`, where `n` is the number of input units in the weight tensor.\n",
    "\n",
    "### Explanation:\n",
    "For a ReLU-activated network, if you were to initialize weights with too small values, you'd risk many neurons being \"dead\" (always outputting 0) because the output of the ReLU function for negative inputs is 0. If you initialize with too large values, the activations might explode to very large numbers, making training unstable.\n",
    "\n",
    "By using He Initialization, you're taking into account the architecture (specifically the choice of ReLU activations) to select an initialization scheme that helps in achieving faster and more stable convergence during training.\n",
    "\n",
    "### In Practice:\n",
    "When initializing layers in popular deep learning frameworks, you can often specify the initialization method. For instance, in TensorFlow/Keras, if you were defining a dense layer for our deep CNN, you might do something like:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "layer = Dense(128, activation='relu', kernel_initializer=HeNormal())\n",
    "```\n",
    "\n",
    "In this example, the choice of the HeNormal initializer directly stems from our architectural decision to use ReLU activations in our deep CNN model. \"\"\"},\n",
    "  {\"role\": \"user\", \"content\": \"\"\"\"How would you select the optimum hyperparameters based on a models architecture? \"\"\"}, \n",
    "  {\"role\": \"assistant\", \"content\": \"\"\"\"Yes, I can provide guidance on identifying optimal hyperparameters based on typical model architectures, but it's essential to understand that the \"optimum\" is often data-dependent and might require actual experiments to be definitively identified. Here's how you can approach selecting hyperparameters for common architectures:\n",
    "\n",
    "### 1. Feed-Forward Neural Networks (Dense Networks):\n",
    "\n",
    "- **Learning rate**: Start around 0.01, but consider a range from 0.001 to 0.1.\n",
    "- **Batch size**: Typically between 32 to 256. Larger batches may lead to faster training but might generalize less well.\n",
    "- **Weight initialization**: Xavier/Glorot initialization.\n",
    "- **Activation**: ReLU, but consider leaky ReLU for deeper networks to prevent dying neurons.\n",
    "- **Optimizer**: SGD with momentum or adaptive optimizers like Adam.\n",
    "\n",
    "### 2. Convolutional Neural Networks (CNNs):\n",
    "\n",
    "- **Learning rate**: Often lower than dense networks; start with 0.001.\n",
    "- **Batch size**: Between 16 to 128. Due to GPU memory constraints and the size of the images.\n",
    "- **Weight initialization**: He initialization (because of the ReLU activations).\n",
    "- **Optimizer**: Adam is frequently used, but SGD with momentum and learning rate schedules can work great too.\n",
    "- **Filter size**: 3x3 is very common, but 5x5 or 1x1 can also be used in specific layers.\n",
    "- **Number of filters**: Doubling the number as you go deeper into the network is a common approach (e.g., 32, 64, 128).\n",
    "- **Pooling**: Max pooling with 2x2 filters and a stride of 2.\n",
    "- **Regularization**: Dropout, with rates between 0.3 to 0.5, often after pooling layers or before fully connected layers.\n",
    "\n",
    "### 3. Recurrent Neural Networks (RNNs):\n",
    "\n",
    "- **Learning rate**: Start with 0.001.\n",
    "- **Batch size**: Between 32 to 128, though some sequence tasks might require smaller batches.\n",
    "- **Weight initialization**: Xavier/Glorot for the internal matrices.\n",
    "- **Activation**: tanh for traditional RNNs. If using LSTMs/GRUs, they have their internal activations (usually sigmoid and tanh).\n",
    "- **Optimizer**: Adam is a popular choice.\n",
    "- **Sequence length**: Depends on the task; for long texts, consider 50-200 words/tokens. For shorter sequences like time series, the actual sequence length or smaller chunks might work.\n",
    "- **Regularization**: Dropout, often on the input and output connections of the RNN units. LSTMs in Keras, for example, offer `dropout` and `recurrent_dropout` parameters.\n",
    "\n",
    "### 4. Transformer Architectures (like BERT, GPT):\n",
    "\n",
    "- **Learning rate**: Usually smaller, around 2e-5 to 5e-5.\n",
    "- **Batch size**: Due to memory constraints, often between 8 to 32.\n",
    "- **Optimizer**: AdamW (a variant of Adam with weight decay).\n",
    "- **Sequence length**: Limited by model design, e.g., 512 for BERT.\n",
    "- **Weight decay**: A small value like 0.01 can help in regularization.\n",
    "\n",
    "### Fine-Tuning:\n",
    "\n",
    "When fine-tuning a pre-trained model:\n",
    "\n",
    "- **Learning rate**: Use a much smaller learning rate than training from scratch, e.g., 1e-5 or even smaller.\n",
    "- **Epochs**: Since the model is already pre-trained, fewer epochs are typically needed. Monitor validation performance to determine the best stopping point.\n",
    "- **Optimizer**: Same as the pre-training phase, but with the reduced learning rate.\n",
    "\n",
    "Remember, these are starting points. The true \"optimum\" hyperparameters often require experimenting on your specific dataset. Regular evaluation on a validation set is crucial to monitor performance and avoid overfitting. Automated hyperparameter optimization tools can also help in searching the vast hyperparameter space more efficiently. \"\"\"}, \n",
    "    {\"role\":\"user\", \"content\":\"\"\"Given the dataset Imagenet 1k what would be the optimal hyperparameters for a model based on the given model architecture?.\n",
    "    \n",
    "ModifiedResNet(\n",
    "  (layer1): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
    "  (layer2): DilatedBlock(\n",
    "    (conv1): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer3): DilatedBlock(\n",
    "    (conv1): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
    "    (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer4): DilatedBlock(\n",
    "    (conv1): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
    "    (skip): Sequential()\n",
    "  )\n",
    "  (layer5): DilatedBlock(\n",
    "    (conv1): Conv2d(512, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (tanh): Tanh()\n",
    "    (conv2): Conv2d(1024, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "    (bn2): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
    "    (skip): Sequential(\n",
    "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "Given this context, provide optimized hyperparameters tailored for training this model on the ImageNet dataset, \n",
    "ensuring that the model generalizes well while preventing overfitting. \n",
    "Your insights into the choices of hyperparameters, \n",
    "especially considering the specified architecture, will be valuable.\n",
    "\n",
    "Format recommended \"Global hyperparameters\" and their corresponding values in a JSON format:\n",
    "{\n",
    "    \"learning_rate\": \"\",\n",
    "    \"batch_size\": \"\",\n",
    "    \"num_epochs\": \"\",\n",
    "    \"optimiser\": \"\",\n",
    "    \"loss_function\": \"\",\n",
    "    \"scheduler\": \"\",\n",
    "    \"step_size\": \"\",\n",
    "    \"gamma\": \"\",\n",
    "    \"momentum\": \"\"    \n",
    "}\n",
    "\"\"\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "816817a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# responses = []\n",
    "# temp=0\n",
    "# try:\n",
    "#     for i in range(10):\n",
    "\n",
    "#         response = openai.ChatCompletion.create(\n",
    "#           model=\"gpt-4\",  \n",
    "#           messages=messages_fvit,\n",
    "#           temperature=temp\n",
    "#         )\n",
    "\n",
    "#         response_content = response['choices'][0]['message']['content']\n",
    "#         print(response_content)\n",
    "        \n",
    "#         responses.append(response_content)\n",
    "\n",
    "#     with open('results_with_context/responses_fastvit.csv', 'w', newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow([\"Response\"])  \n",
    "#         for response in responses:\n",
    "#             writer.writerow([response])\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc24f7b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the architecture, which is a modified ResNet with dilated convolutions and Tanh activations, here are some suggested hyperparameters for training on the ImageNet dataset:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"batch_size\": \"128\",\n",
      "    \"num_epochs\": \"100\",\n",
      "    \"optimizer\": \"Adam\",\n",
      "    \"loss_function\": \"CrossEntropyLoss\",\n",
      "    \"scheduler\": \"StepLR\",\n",
      "    \"step_size\": \"30\",\n",
      "    \"gamma\": \"0.1\",\n",
      "    \"momentum\": \"0.9\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **Learning Rate (0.001)**: A smaller learning rate is chosen considering the complexity of the ImageNet dataset and the depth of the network. This helps in stable and gradual learning.\n",
      "\n",
      "- **Batch Size (128)**: This is a typical batch size for ImageNet training. It might need to be adjusted based on the GPU memory.\n",
      "\n",
      "- **Number of Epochs (100)**: Training for a larger number of epochs is common with complex datasets like ImageNet. Early stopping should be used in conjunction to prevent overfitting.\n",
      "\n",
      "- **Optimizer (Adam)**: Adam is a good default optimizer that adapts the learning rate for each weight and maintains a moving average of past gradients.\n",
      "\n",
      "- **Loss Function (CrossEntropyLoss)**: This is the standard loss function for multi-class classification problems like ImageNet.\n",
      "\n",
      "- **Scheduler (StepLR)**: This reduces the learning rate by a factor of gamma every step_size epochs. It's a simple yet effective learning rate schedule.\n",
      "\n",
      "- **Step Size (30)**: This is the number of epochs after which the learning rate is reduced by a factor of gamma. It's set to a third of the total epochs as a starting point.\n",
      "\n",
      "- **Gamma (0.1)**: This factor reduces the learning rate, helping the model make smaller updates as it converges.\n",
      "\n",
      "- **Momentum (0.9)**: This accelerates the gradient vectors in the right directions, leading to faster convergence. It's not used by Adam but included for completeness.\n",
      "\n",
      "These are starting points and might need to be adjusted based on the validation performance. Techniques like learning rate finder can help identify a good initial learning rate. Regularization techniques like weight decay and dropout might also be needed to prevent overfitting.\n",
      "Given the architecture, which is a modified ResNet with dilated convolutions and Tanh activations, here are some suggested hyperparameters for training on the ImageNet dataset:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"batch_size\": \"128\",\n",
      "    \"num_epochs\": \"100\",\n",
      "    \"optimiser\": \"Adam\",\n",
      "    \"loss_function\": \"CrossEntropyLoss\",\n",
      "    \"scheduler\": \"StepLR\",\n",
      "    \"step_size\": \"30\",\n",
      "    \"gamma\": \"0.1\",\n",
      "    \"momentum\": \"0.9\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **Learning Rate (0.001)**: This is a typical starting point for the learning rate. It might need to be adjusted based on the training progress. If the loss decreases too slowly, you might want to increase this. If the training is unstable, you might want to decrease it.\n",
      "\n",
      "- **Batch Size (128)**: This is a reasonable batch size for ImageNet. It might need to be adjusted based on the memory capacity of your GPU.\n",
      "\n",
      "- **Number of Epochs (100)**: Training on ImageNet is typically a long process. 100 epochs is a common choice, but you might need more or less depending on how quickly your model converges.\n",
      "\n",
      "- **Optimizer (Adam)**: Adam is a good default choice of optimizer. It adapts the learning rate for each weight individually and is generally less sensitive to the initial learning rate.\n",
      "\n",
      "- **Loss Function (CrossEntropyLoss)**: This is the standard loss function for multi-class classification problems like ImageNet.\n",
      "\n",
      "- **Scheduler (StepLR)**: This learning rate scheduler reduces the learning rate by a factor (gamma) every few epochs (step_size). It's a simple and often effective schedule.\n",
      "\n",
      "- **Step Size (30)**: This means the learning rate will be reduced every 30 epochs. This is a somewhat arbitrary choice and might need to be adjusted based on the training progress.\n",
      "\n",
      "- **Gamma (0.1)**: This is the factor by which the learning rate is reduced. So every 30 epochs, the learning rate will be multiplied by 0.1.\n",
      "\n",
      "- **Momentum (0.9)**: This is a typical choice of momentum. It can help speed up training and avoid local minima.\n",
      "\n",
      "Please note that these are initial suggestions. Hyperparameters often need to be tuned based on the specific dataset and model architecture. Regular evaluation on a validation set is crucial to monitor performance and avoid overfitting. Automated hyperparameter optimization tools can also help in searching the vast hyperparameter space more efficiently.\n",
      "Given the architecture, which is a variant of ResNet with dilated convolutions and Tanh activations, here are some suggested hyperparameters for training on the ImageNet dataset:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"batch_size\": \"128\",\n",
      "    \"num_epochs\": \"100\",\n",
      "    \"optimiser\": \"Adam\",\n",
      "    \"loss_function\": \"CrossEntropyLoss\",\n",
      "    \"scheduler\": \"StepLR\",\n",
      "    \"step_size\": \"30\",\n",
      "    \"gamma\": \"0.1\",\n",
      "    \"momentum\": \"0.9\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **Learning Rate (0.001)**: This is a typical starting point for the learning rate. However, it's often beneficial to use a learning rate scheduler that reduces the learning rate as training progresses.\n",
      "\n",
      "- **Batch Size (128)**: This is a reasonable batch size that should fit on most GPUs. The optimal batch size can depend on the specific GPU memory available.\n",
      "\n",
      "- **Number of Epochs (100)**: This is a typical number of epochs for training on large datasets like ImageNet. The exact number can vary, and early stopping should be used to prevent overfitting.\n",
      "\n",
      "- **Optimizer (Adam)**: Adam is a good default choice for an optimizer as it automatically adjusts the learning rate during training.\n",
      "\n",
      "- **Loss Function (CrossEntropyLoss)**: This is the standard loss function for multi-class classification problems like ImageNet.\n",
      "\n",
      "- **Scheduler (StepLR)**: This learning rate scheduler reduces the learning rate by a factor of `gamma` every `step_size` epochs. It's a simple and often effective schedule.\n",
      "\n",
      "- **Step Size (30)**: This means the learning rate will be reduced every 30 epochs. The exact number can be tuned.\n",
      "\n",
      "- **Gamma (0.1)**: This is the factor by which the learning rate is reduced. So the learning rate will be multiplied by 0.1 every 30 epochs.\n",
      "\n",
      "- **Momentum (0.9)**: This is a typical value for momentum, which helps accelerate the optimizer in the relevant direction and dampens oscillations.\n",
      "\n",
      "These are just starting points and should be further tuned based on validation set performance. Also, regularization techniques like weight decay and dropout might be beneficial to prevent overfitting.\n",
      "Given the architecture, which is a modified ResNet with dilated convolutions and Tanh activations, here are some suggested hyperparameters for training on the ImageNet dataset:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"batch_size\": \"128\",\n",
      "    \"num_epochs\": \"100\",\n",
      "    \"optimizer\": \"Adam\",\n",
      "    \"loss_function\": \"CrossEntropyLoss\",\n",
      "    \"scheduler\": \"StepLR\",\n",
      "    \"step_size\": \"30\",\n",
      "    \"gamma\": \"0.1\",\n",
      "    \"momentum\": \"0.9\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **Learning Rate (0.001)**: This is a common starting point for the learning rate. It might need to be adjusted based on the training progress. If the loss decreases too slowly, you might want to increase this. If the training is unstable, you might want to decrease this.\n",
      "\n",
      "- **Batch Size (128)**: This is a typical batch size for ImageNet training. It might need to be adjusted based on the memory capacity of your GPU.\n",
      "\n",
      "- **Number of Epochs (100)**: This is a typical number of epochs for training on ImageNet. You might want to use early stopping based on validation performance to prevent overfitting.\n",
      "\n",
      "- **Optimizer (Adam)**: Adam is a good default optimizer that adapts the learning rate for each weight individually. It's often used in deep learning applications.\n",
      "\n",
      "- **Loss Function (CrossEntropyLoss)**: This is the standard loss function for multi-class classification problems like ImageNet.\n",
      "\n",
      "- **Scheduler (StepLR)**: This learning rate scheduler reduces the learning rate by a factor (gamma) every few epochs (step_size). This is a common strategy to help the optimizer converge.\n",
      "\n",
      "- **Step Size (30)**: This means the learning rate will be reduced every 30 epochs. This is a common setting, but it might need to be adjusted based on how quickly your training loss is decreasing.\n",
      "\n",
      "- **Gamma (0.1)**: This is the factor by which the learning rate will be reduced. So every 30 epochs, the learning rate will be multiplied by 0.1.\n",
      "\n",
      "- **Momentum (0.9)**: This is a typical value for momentum, which helps accelerate the optimizer in the right direction and dampens oscillations.\n",
      "\n",
      "These are just starting points and might need to be adjusted based on the specifics of your training progress and validation performance. It's also a good idea to use techniques like data augmentation and weight decay for regularization to prevent overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the architecture, which is a modified ResNet with dilated convolutions and Tanh activations, here are some suggested hyperparameters for training on the ImageNet dataset:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"batch_size\": \"128\",\n",
      "    \"num_epochs\": \"100\",\n",
      "    \"optimizer\": \"Adam\",\n",
      "    \"loss_function\": \"CrossEntropyLoss\",\n",
      "    \"scheduler\": \"StepLR\",\n",
      "    \"step_size\": \"30\",\n",
      "    \"gamma\": \"0.1\",\n",
      "    \"momentum\": \"0.9\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **Learning Rate (0.001)**: This is a typical starting point for the learning rate. It might need to be adjusted based on the training progress. If the loss decreases too slowly, you might want to increase this. If the training is unstable, you might want to decrease it.\n",
      "\n",
      "- **Batch Size (128)**: This is a reasonable batch size for ImageNet. It might need to be adjusted based on the memory capacity of your GPU.\n",
      "\n",
      "- **Number of Epochs (100)**: Training on ImageNet is a large task, so we'll start with a large number of epochs. You should monitor the validation loss and use early stopping to prevent overfitting.\n",
      "\n",
      "- **Optimizer (Adam)**: Adam is a good default choice of optimizer. It adapts the learning rate for each weight individually and is generally less sensitive to the initial learning rate.\n",
      "\n",
      "- **Loss Function (CrossEntropyLoss)**: This is the standard loss function for multi-class classification problems like ImageNet.\n",
      "\n",
      "- **Scheduler (StepLR)**: This learning rate scheduler reduces the learning rate by a factor of `gamma` every `step_size` epochs. It's a simple and often effective schedule.\n",
      "\n",
      "- **Step Size (30)**: This is the number of epochs before the learning rate drops, a typical setting for ImageNet training.\n",
      "\n",
      "- **Gamma (0.1)**: This is the factor by which the learning rate decreases, a typical setting.\n",
      "\n",
      "- **Momentum (0.9)**: This is a typical value for momentum, which can help accelerate learning and navigate through noisy gradients.\n",
      "\n",
      "Remember, these are starting points. You should monitor the training and validation loss and adjust the hyperparameters as necessary. Also, consider using techniques like data augmentation, weight decay, and dropout to improve generalization and prevent overfitting.\n",
      "Given the architecture, which is a modified ResNet with dilated convolutions and Tanh activations, here are some suggested hyperparameters for training on the ImageNet dataset:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"batch_size\": \"128\",\n",
      "    \"num_epochs\": \"100\",\n",
      "    \"optimiser\": \"Adam\",\n",
      "    \"loss_function\": \"CrossEntropyLoss\",\n",
      "    \"scheduler\": \"StepLR\",\n",
      "    \"step_size\": \"30\",\n",
      "    \"gamma\": \"0.1\",\n",
      "    \"momentum\": \"0.9\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **Learning Rate (0.001)**: This is a typical starting point for the learning rate. It might need to be adjusted based on the training progress.\n",
      "\n",
      "- **Batch Size (128)**: This is a reasonable batch size for ImageNet, which has high-resolution images. The exact value might need to be adjusted based on the GPU memory.\n",
      "\n",
      "- **Number of Epochs (100)**: Training on ImageNet usually takes a significant number of epochs. However, early stopping should be used to prevent overfitting.\n",
      "\n",
      "- **Optimizer (Adam)**: Adam is a good default choice of optimizer. It adapts the learning rate for each weight individually and is generally less sensitive to the initial learning rate.\n",
      "\n",
      "- **Loss Function (CrossEntropyLoss)**: This is the standard loss function for multi-class classification problems like ImageNet.\n",
      "\n",
      "- **Scheduler (StepLR)**: This reduces the learning rate by a factor of gamma every step_size epochs. It's a simple and often effective learning rate schedule.\n",
      "\n",
      "- **Step Size (30)**: This is a reasonable starting point, reducing the learning rate every 30 epochs. It might need to be adjusted based on the training progress.\n",
      "\n",
      "- **Gamma (0.1)**: This reduces the learning rate to 10% of its value every step_size epochs.\n",
      "\n",
      "- **Momentum (0.9)**: This is a typical value for momentum, which can help accelerate learning, especially in the earlier stages of training.\n",
      "\n",
      "These are just starting points and might need to be adjusted based on the training progress. For example, if the model is overfitting, you might want to increase the strength of regularization (e.g., weight decay) or reduce the complexity of the model (e.g., number of layers or number of units per layer). If the model is underfitting, you might want to increase the model complexity or the learning rate, or train for more epochs.\n",
      "Given the architecture, which is a modified ResNet with dilated convolutions and Tanh activations, here are some suggested hyperparameters for training on the ImageNet dataset:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"batch_size\": \"128\",\n",
      "    \"num_epochs\": \"100\",\n",
      "    \"optimizer\": \"Adam\",\n",
      "    \"loss_function\": \"CrossEntropyLoss\",\n",
      "    \"scheduler\": \"StepLR\",\n",
      "    \"step_size\": \"30\",\n",
      "    \"gamma\": \"0.1\",\n",
      "    \"momentum\": \"0.9\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **Learning Rate (0.001)**: This is a typical starting point for the learning rate. It might need to be adjusted based on the training progress. If the loss decreases too slowly, consider increasing it. If the training is unstable with loss going up and down, consider decreasing it.\n",
      "\n",
      "- **Batch Size (128)**: This is a reasonable batch size for ImageNet. It might need to be adjusted based on the GPU memory. If you have more memory, you can increase it for potentially faster training.\n",
      "\n",
      "- **Number of Epochs (100)**: Training on ImageNet usually takes a lot of epochs because of the large amount of data. Monitor the validation accuracy and stop training if it stops increasing for a significant number of epochs.\n",
      "\n",
      "- **Optimizer (Adam)**: Adam is a good default optimizer. It adapts the learning rate for each weight individually and is less sensitive to the initial learning rate.\n",
      "\n",
      "- **Loss Function (CrossEntropyLoss)**: This is the standard loss function for multi-class classification problems like ImageNet.\n",
      "\n",
      "- **Scheduler (StepLR)**: This learning rate scheduler decreases the learning rate by a factor (gamma) every few epochs (step size). It can help to avoid overshooting the minimum of the loss function.\n",
      "\n",
      "- **Step Size (30)**: This means the learning rate will be reduced every 30 epochs. This is a reasonable starting point, but it might need to be adjusted based on how fast the validation accuracy plateaus.\n",
      "\n",
      "- **Gamma (0.1)**: This is the factor by which the learning rate is reduced. So after 30 epochs, the learning rate will be 10% of the initial learning rate.\n",
      "\n",
      "- **Momentum (0.9)**: This is a typical value for momentum, which helps to accelerate training. It's not used by Adam, but it's included in case you want to switch to SGD or another optimizer that uses momentum.\n",
      "\n",
      "Remember, these are just starting points. Hyperparameter tuning often requires experimentation and adjustment based on the training progress.\n",
      "Given the architecture, which is a modified ResNet with dilated convolutions and Tanh activations, here are some suggested hyperparameters for training on the ImageNet dataset:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"batch_size\": \"64\",\n",
      "    \"num_epochs\": \"100\",\n",
      "    \"optimiser\": \"Adam\",\n",
      "    \"loss_function\": \"CrossEntropyLoss\",\n",
      "    \"scheduler\": \"StepLR\",\n",
      "    \"step_size\": \"30\",\n",
      "    \"gamma\": \"0.1\",\n",
      "    \"momentum\": \"0.9\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **Learning Rate (0.001)**: This is a common starting point for the learning rate. It might need to be adjusted based on the training progress. If the model is not learning, try a higher rate; if the training is unstable, try a lower rate.\n",
      "\n",
      "- **Batch Size (64)**: This is a reasonable batch size that should fit in the GPU memory. Larger batches can lead to more stable gradients, but smaller batches can have a regularizing effect.\n",
      "\n",
      "- **Number of Epochs (100)**: This is a typical number of epochs for training on ImageNet. It might need to be adjusted based on the training progress.\n",
      "\n",
      "- **Optimizer (Adam)**: Adam is a good default optimizer that automatically adjusts the learning rate based on the gradient statistics.\n",
      "\n",
      "- **Loss Function (CrossEntropyLoss)**: This is the standard loss function for multi-class classification problems like ImageNet.\n",
      "\n",
      "- **Scheduler (StepLR)**: This scheduler reduces the learning rate by a factor (gamma) every few epochs (step size). It can help the model to converge faster in the later stages of training.\n",
      "\n",
      "- **Step Size (30)**: This means the learning rate will be reduced every 30 epochs. It's a reasonable starting point, but might need to be adjusted based on the training progress.\n",
      "\n",
      "- **Gamma (0.1)**: This is the factor by which the learning rate will be reduced. A value of 0.1 means the learning rate will be multiplied by 0.1.\n",
      "\n",
      "- **Momentum (0.9)**: This is a typical value for momentum, which can help to accelerate the optimizer in the relevant direction and dampen oscillations.\n",
      "\n",
      "These are just starting points and might need to be adjusted based on the training progress and validation performance. It's also recommended to use techniques like early stopping, checkpointing, and data augmentation to improve the model's performance and prevent overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the architecture, which is a modified ResNet with dilated convolutions and Tanh activations, and the dataset, which is ImageNet, here's a set of hyperparameters that could be a good starting point:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"batch_size\": \"64\",\n",
      "    \"num_epochs\": \"100\",\n",
      "    \"optimiser\": \"Adam\",\n",
      "    \"loss_function\": \"CrossEntropyLoss\",\n",
      "    \"scheduler\": \"StepLR\",\n",
      "    \"step_size\": \"30\",\n",
      "    \"gamma\": \"0.1\",\n",
      "    \"momentum\": \"0.9\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **Learning Rate (0.001)**: This is a typical starting point for the learning rate. It might need to be adjusted based on the training progress. If the model isn't learning, you might need to increase it. If the training is unstable, you might need to decrease it.\n",
      "\n",
      "- **Batch Size (64)**: This is a reasonable batch size for ImageNet. It might need to be adjusted based on the memory capacity of your GPU.\n",
      "\n",
      "- **Number of Epochs (100)**: Training on ImageNet is typically a long process. 100 epochs is a common choice, but you might need to adjust this based on how quickly your model is converging.\n",
      "\n",
      "- **Optimizer (Adam)**: Adam is a good default choice of optimizer. It adapts the learning rate for each weight individually and is generally less sensitive to the initial learning rate.\n",
      "\n",
      "- **Loss Function (CrossEntropyLoss)**: This is the standard loss function for multi-class classification problems like ImageNet.\n",
      "\n",
      "- **Scheduler (StepLR)**: This reduces the learning rate by a factor (gamma) every few epochs (step_size). It's a simple and often effective learning rate schedule.\n",
      "\n",
      "- **Step Size (30)**: This means the learning rate will be reduced every 30 epochs. This is a heuristic and might need to be adjusted based on your specific training dynamics.\n",
      "\n",
      "- **Gamma (0.1)**: This is the factor by which the learning rate will be reduced. So every 30 epochs, the learning rate will be multiplied by 0.1.\n",
      "\n",
      "- **Momentum (0.9)**: This is a typical value for momentum, which helps accelerate gradient descent in the relevant direction and dampens oscillations.\n",
      "\n",
      "Remember, these are just starting points. You will likely need to adjust these hyperparameters based on the specifics of your training process and the performance of your model on a validation set.\n",
      "Given the architecture, which is a modified ResNet with dilated convolutions and Tanh activations, here are some suggested hyperparameters for training on the ImageNet dataset:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"batch_size\": \"64\",\n",
      "    \"num_epochs\": \"100\",\n",
      "    \"optimiser\": \"Adam\",\n",
      "    \"loss_function\": \"CrossEntropyLoss\",\n",
      "    \"scheduler\": \"StepLR\",\n",
      "    \"step_size\": \"30\",\n",
      "    \"gamma\": \"0.1\",\n",
      "    \"momentum\": \"0.9\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **Learning Rate (0.001)**: This is a typical starting point for the learning rate. It might need to be adjusted based on the training progress. If the model isn't learning, try a higher rate; if training is unstable, try a lower rate.\n",
      "\n",
      "- **Batch Size (64)**: This is a reasonable batch size for ImageNet, which has high-resolution images. The optimal value can depend on the memory capacity of your GPU.\n",
      "\n",
      "- **Number of Epochs (100)**: Training on ImageNet is a large task, so a higher number of epochs is usually needed. Monitor the validation loss and accuracy to decide when to stop.\n",
      "\n",
      "- **Optimizer (Adam)**: Adam is a good default optimizer that adapts the learning rate for each weight and maintains a moving average of past gradients.\n",
      "\n",
      "- **Loss Function (CrossEntropyLoss)**: This is the standard loss function for multi-class classification tasks like ImageNet.\n",
      "\n",
      "- **Scheduler (StepLR)**: This reduces the learning rate by a factor (`gamma`) every `step_size` epochs. It's a simple and often effective learning rate schedule.\n",
      "\n",
      "- **Step Size (30)**: This means the learning rate will be reduced every 30 epochs. The value can be adjusted based on how quickly the model is learning.\n",
      "\n",
      "- **Gamma (0.1)**: This is the factor by which the learning rate is reduced. So, every 30 epochs, the learning rate will be multiplied by 0.1.\n",
      "\n",
      "- **Momentum (0.9)**: This is a typical value for momentum, which helps accelerate learning and navigate the parameter space more effectively. Note that momentum is used in optimizers like SGD, but in Adam, this concept is replaced by the moving averages of past gradients.\n",
      "\n",
      "Remember, these are starting points. Monitor the training and validation metrics and adjust the hyperparameters as needed. Also, consider techniques like early stopping, checkpointing, and data augmentation to improve performance and prevent overfitting.\n"
     ]
    }
   ],
   "source": [
    "# output_file_name = f'output_prompt_MLP.txt'\n",
    "# output_file = open(output_file_name, 'w')\n",
    "# sys.stdout = output_file\n",
    "\n",
    "num_executions = 10\n",
    "temp = 0\n",
    "\n",
    "fine_tuning_df = pd.DataFrame(columns=['Learning Rate', 'Momentum', 'Batch Size', 'Num Epochs', 'Optimizer',\n",
    "                                      'Loss Function', 'Scheduler', 'Step Size', 'Gamma'])\n",
    "\n",
    "\n",
    "for i in range(num_executions):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "#             messages=[\n",
    "# #                 {\"role\": \"system\", \"content\": system_prompt},\n",
    "#                 {\"role\": \"user\", \"content\": prompt_fastvit_ifcresults}\n",
    "#             ],\n",
    "            temperature=temp\n",
    "        )\n",
    "    except Exception:\n",
    "        sleep(3)\n",
    "        print('Limit exceeded!')\n",
    "        continue\n",
    "\n",
    "    completion = response.choices[0]['message']['content']\n",
    "    print(completion)\n",
    "\n",
    "    start_index = completion.find('{')\n",
    "    end_index = completion.rfind('}') + 1\n",
    "    json_string = completion[start_index:end_index]\n",
    "\n",
    "    try:\n",
    "        completion_dict = json.loads(json_string)\n",
    "\n",
    "        learning_rate = completion_dict.get('learning_rate')\n",
    "        momentum = completion_dict.get('momentum')\n",
    "        batch_size = completion_dict.get('batch_size')\n",
    "        num_epochs = completion_dict.get('num_epochs')\n",
    "        optimizer = completion_dict.get('optimizer')\n",
    "        loss_function = completion_dict.get('loss_function')\n",
    "        scheduler = completion_dict.get('scheduler')\n",
    "        step_size = completion_dict.get('step_size')\n",
    "        gamma = completion_dict.get('gamma')\n",
    "\n",
    "        fine_tuning_df.loc[i] = [learning_rate, momentum, batch_size, num_epochs, optimizer,\n",
    "                                     loss_function, scheduler, step_size, gamma]\n",
    "\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print('Could not decode the completion as JSON.')\n",
    "fine_tuning_df.to_csv('results_with_context_new/training_resnet_modified.csv', index=False)\n",
    "sleep(3)\n",
    "# output_file.close()\n",
    "# sys.stdout = sys.__stdout__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
